{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>9.090909e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1762</td>\n",
       "      <td>0</td>\n",
       "      <td>1.250000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1068</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666667e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2126</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>784</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666667e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1384</td>\n",
       "      <td>0</td>\n",
       "      <td>3.571429e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1454</td>\n",
       "      <td>0</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2062</td>\n",
       "      <td>0</td>\n",
       "      <td>1.428571e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2040</td>\n",
       "      <td>0</td>\n",
       "      <td>9.090909e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1052</td>\n",
       "      <td>0</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1774</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1568</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2054</td>\n",
       "      <td>0</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2170</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1.111111e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1334</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2058</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>1.428571e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>902</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666667e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1626</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "      <td>1.428571e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1.434166</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>530</td>\n",
       "      <td>268</td>\n",
       "      <td>1.045904e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82302</th>\n",
       "      <td>82303</td>\n",
       "      <td>0.449797</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>588</td>\n",
       "      <td>268</td>\n",
       "      <td>3.334838e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82303</th>\n",
       "      <td>82304</td>\n",
       "      <td>0.870010</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>588</td>\n",
       "      <td>268</td>\n",
       "      <td>1.724118e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82304</th>\n",
       "      <td>82305</td>\n",
       "      <td>1.766424</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>588</td>\n",
       "      <td>354</td>\n",
       "      <td>9.623964e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82305</th>\n",
       "      <td>82306</td>\n",
       "      <td>1.025080</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>588</td>\n",
       "      <td>268</td>\n",
       "      <td>1.463300e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82306</th>\n",
       "      <td>82307</td>\n",
       "      <td>0.498365</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>588</td>\n",
       "      <td>268</td>\n",
       "      <td>3.009842e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82307</th>\n",
       "      <td>82308</td>\n",
       "      <td>0.971427</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>588</td>\n",
       "      <td>354</td>\n",
       "      <td>1.750003e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82308</th>\n",
       "      <td>82309</td>\n",
       "      <td>0.467263</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>588</td>\n",
       "      <td>268</td>\n",
       "      <td>3.210183e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82309</th>\n",
       "      <td>82310</td>\n",
       "      <td>1.026355</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>588</td>\n",
       "      <td>354</td>\n",
       "      <td>1.656347e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82310</th>\n",
       "      <td>82311</td>\n",
       "      <td>1.363057</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>588</td>\n",
       "      <td>354</td>\n",
       "      <td>1.247196e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82311</th>\n",
       "      <td>82312</td>\n",
       "      <td>0.888738</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>588</td>\n",
       "      <td>268</td>\n",
       "      <td>1.687786e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82312</th>\n",
       "      <td>82313</td>\n",
       "      <td>1.173606</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>588</td>\n",
       "      <td>354</td>\n",
       "      <td>1.448527e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82313</th>\n",
       "      <td>82314</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>1.111111e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82314</th>\n",
       "      <td>82315</td>\n",
       "      <td>0.524434</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>588</td>\n",
       "      <td>268</td>\n",
       "      <td>2.860227e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82315</th>\n",
       "      <td>82316</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82316</th>\n",
       "      <td>82317</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82317</th>\n",
       "      <td>82318</td>\n",
       "      <td>0.947039</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>588</td>\n",
       "      <td>268</td>\n",
       "      <td>1.583884e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82318</th>\n",
       "      <td>82319</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>1.111111e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82319</th>\n",
       "      <td>82320</td>\n",
       "      <td>0.811914</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>588</td>\n",
       "      <td>268</td>\n",
       "      <td>1.847486e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82320</th>\n",
       "      <td>82321</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82321</th>\n",
       "      <td>82322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82322</th>\n",
       "      <td>82323</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82323</th>\n",
       "      <td>82324</td>\n",
       "      <td>5.167410</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>24</td>\n",
       "      <td>138067</td>\n",
       "      <td>1042</td>\n",
       "      <td>2.535119e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82324</th>\n",
       "      <td>82325</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666667e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82325</th>\n",
       "      <td>82326</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82326</th>\n",
       "      <td>82327</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>1.111111e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82327</th>\n",
       "      <td>82328</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82328</th>\n",
       "      <td>82329</td>\n",
       "      <td>1.106101</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>18062</td>\n",
       "      <td>354</td>\n",
       "      <td>2.441007e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82329</th>\n",
       "      <td>82330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82330</th>\n",
       "      <td>82331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82331</th>\n",
       "      <td>82332</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>1.111111e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82332 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id       dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
       "0          1  0.000011    117        0      4      2      0     496       0   \n",
       "1          2  0.000008    117        0      4      2      0    1762       0   \n",
       "2          3  0.000005    117        0      4      2      0    1068       0   \n",
       "3          4  0.000006    117        0      4      2      0     900       0   \n",
       "4          5  0.000010    117        0      4      2      0    2126       0   \n",
       "5          6  0.000003    117        0      4      2      0     784       0   \n",
       "6          7  0.000006    117        0      4      2      0    1960       0   \n",
       "7          8  0.000028    117        0      4      2      0    1384       0   \n",
       "8          9  0.000000      6        0      4      1      0      46       0   \n",
       "9         10  0.000000      6        0      4      1      0      46       0   \n",
       "10        11  0.000000      6        0      4      1      0      46       0   \n",
       "11        12  0.000000      6        0      4      1      0      46       0   \n",
       "12        13  0.000004    117        0      4      2      0    1454       0   \n",
       "13        14  0.000007    117        0      4      2      0    2062       0   \n",
       "14        15  0.000011    117        0      4      2      0    2040       0   \n",
       "15        16  0.000004    117        0      4      2      0    1052       0   \n",
       "16        17  0.000003    117        0      4      2      0     314       0   \n",
       "17        18  0.000010    117        0      4      2      0    1774       0   \n",
       "18        19  0.000002    117        0      4      2      0    1568       0   \n",
       "19        20  0.000004    117        0      4      2      0    2054       0   \n",
       "20        21  0.000010    117        0      4      2      0    2170       0   \n",
       "21        22  0.000009    117        0      4      2      0     202       0   \n",
       "22        23  0.000010    117        0      4      2      0    1334       0   \n",
       "23        24  0.000005    117        0      4      2      0    2058       0   \n",
       "24        25  0.000003    117        0      4      2      0     286       0   \n",
       "25        26  0.000007    117        0      4      2      0    1500       0   \n",
       "26        27  0.000006    117        0      4      2      0     902       0   \n",
       "27        28  0.000002    117        0      4      2      0    1626       0   \n",
       "28        29  0.000007    117        0      4      2      0     364       0   \n",
       "29        30  1.434166    111        0      3     10      6     530     268   \n",
       "...      ...       ...    ...      ...    ...    ...    ...     ...     ...   \n",
       "82302  82303  0.449797    111        0      3     10      6     588     268   \n",
       "82303  82304  0.870010    111        0      3     10      6     588     268   \n",
       "82304  82305  1.766424    111        0      3     10      8     588     354   \n",
       "82305  82306  1.025080    111        0      3     10      6     588     268   \n",
       "82306  82307  0.498365    111        0      3     10      6     588     268   \n",
       "82307  82308  0.971427    111        0      3     10      8     588     354   \n",
       "82308  82309  0.467263    111        0      3     10      6     588     268   \n",
       "82309  82310  1.026355    111        0      3     10      8     588     354   \n",
       "82310  82311  1.363057    111        0      3     10      8     588     354   \n",
       "82311  82312  0.888738    111        0      3     10      6     588     268   \n",
       "82312  82313  1.173606    111        0      3     10      8     588     354   \n",
       "82313  82314  0.000009    117        0      4      2      0     104       0   \n",
       "82314  82315  0.524434    111        0      3     10      6     588     268   \n",
       "82315  82316  0.000001    117        0      4      2      0     104       0   \n",
       "82316  82317  0.000001    117        0      4      2      0     104       0   \n",
       "82317  82318  0.947039    111        0      3     10      6     588     268   \n",
       "82318  82319  0.000009    117        0      4      2      0     104       0   \n",
       "82319  82320  0.811914    111        0      3     10      6     588     268   \n",
       "82320  82321  0.000010    117        0      4      2      0     104       0   \n",
       "82321  82322  0.000001    117        0      4      2      0     104       0   \n",
       "82322  82323  0.000004    117        0      4      2      0     104       0   \n",
       "82323  82324  5.167410    111        0      3    108     24  138067    1042   \n",
       "82324  82325  0.000006    117        0      4      2      0     104       0   \n",
       "82325  82326  0.000010    117        0      4      2      0     104       0   \n",
       "82326  82327  0.000009    117        0      4      2      0     104       0   \n",
       "82327  82328  0.000005    117        0      4      2      0     104       0   \n",
       "82328  82329  1.106101    111        0      3     20      8   18062     354   \n",
       "82329  82330  0.000000      6        0      4      1      0      46       0   \n",
       "82330  82331  0.000000      6        0      4      1      0      46       0   \n",
       "82331  82332  0.000009    117        0      4      2      0     104       0   \n",
       "\n",
       "               rate  ...    ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
       "0      9.090909e+04  ...                   1               2             0   \n",
       "1      1.250000e+05  ...                   1               2             0   \n",
       "2      2.000000e+05  ...                   1               3             0   \n",
       "3      1.666667e+05  ...                   1               3             0   \n",
       "4      1.000000e+05  ...                   1               3             0   \n",
       "5      3.333333e+05  ...                   1               2             0   \n",
       "6      1.666667e+05  ...                   1               2             0   \n",
       "7      3.571429e+04  ...                   1               3             0   \n",
       "8      0.000000e+00  ...                   2               2             0   \n",
       "9      0.000000e+00  ...                   2               2             0   \n",
       "10     0.000000e+00  ...                   2               2             0   \n",
       "11     0.000000e+00  ...                   2               2             0   \n",
       "12     2.500000e+05  ...                   1               3             0   \n",
       "13     1.428571e+05  ...                   1               3             0   \n",
       "14     9.090909e+04  ...                   1               1             0   \n",
       "15     2.500000e+05  ...                   1               3             0   \n",
       "16     3.333333e+05  ...                   1               2             0   \n",
       "17     1.000000e+05  ...                   1               2             0   \n",
       "18     5.000000e+05  ...                   1               2             0   \n",
       "19     2.500000e+05  ...                   1               2             0   \n",
       "20     1.000000e+05  ...                   1               2             0   \n",
       "21     1.111111e+05  ...                   1               2             0   \n",
       "22     1.000000e+05  ...                   1               3             0   \n",
       "23     2.000000e+05  ...                   1               3             0   \n",
       "24     3.333333e+05  ...                   1               3             0   \n",
       "25     1.428571e+05  ...                   1               2             0   \n",
       "26     1.666667e+05  ...                   1               2             0   \n",
       "27     5.000000e+05  ...                   1               1             0   \n",
       "28     1.428571e+05  ...                   1               1             0   \n",
       "29     1.045904e+01  ...                   1               1             0   \n",
       "...             ...  ...                 ...             ...           ...   \n",
       "82302  3.334838e+01  ...                   1               2             0   \n",
       "82303  1.724118e+01  ...                   1               2             0   \n",
       "82304  9.623964e+00  ...                   1               1             0   \n",
       "82305  1.463300e+01  ...                   1               1             0   \n",
       "82306  3.009842e+01  ...                   1               1             0   \n",
       "82307  1.750003e+01  ...                   1               2             0   \n",
       "82308  3.210183e+01  ...                   1               2             0   \n",
       "82309  1.656347e+01  ...                   1               2             0   \n",
       "82310  1.247196e+01  ...                   1               2             0   \n",
       "82311  1.687786e+01  ...                   1               2             0   \n",
       "82312  1.448527e+01  ...                   1               1             0   \n",
       "82313  1.111111e+05  ...                   1               1             0   \n",
       "82314  2.860227e+01  ...                   1               1             0   \n",
       "82315  1.000000e+06  ...                   1               2             0   \n",
       "82316  1.000000e+06  ...                   1               2             0   \n",
       "82317  1.583884e+01  ...                   1               4             0   \n",
       "82318  1.111111e+05  ...                   1               2             0   \n",
       "82319  1.847486e+01  ...                   1               4             0   \n",
       "82320  1.000000e+05  ...                   1               2             0   \n",
       "82321  1.000000e+06  ...                   1               2             0   \n",
       "82322  2.500000e+05  ...                   1               1             0   \n",
       "82323  2.535119e+01  ...                   1               1             0   \n",
       "82324  1.666667e+05  ...                   1               2             0   \n",
       "82325  1.000000e+05  ...                   1               2             0   \n",
       "82326  1.111111e+05  ...                   1               1             0   \n",
       "82327  2.000000e+05  ...                   1               2             0   \n",
       "82328  2.441007e+01  ...                   1               1             0   \n",
       "82329  0.000000e+00  ...                   1               1             0   \n",
       "82330  0.000000e+00  ...                   1               1             0   \n",
       "82331  1.111111e+05  ...                   1               1             0   \n",
       "\n",
       "       ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
       "0               0                 0           1           2                0   \n",
       "1               0                 0           1           2                0   \n",
       "2               0                 0           1           3                0   \n",
       "3               0                 0           2           3                0   \n",
       "4               0                 0           2           3                0   \n",
       "5               0                 0           2           2                0   \n",
       "6               0                 0           2           2                0   \n",
       "7               0                 0           1           3                0   \n",
       "8               0                 0           2           2                1   \n",
       "9               0                 0           2           2                1   \n",
       "10              0                 0           2           2                1   \n",
       "11              0                 0           2           2                1   \n",
       "12              0                 0           1           3                0   \n",
       "13              0                 0           1           3                0   \n",
       "14              0                 0           1           1                0   \n",
       "15              0                 0           2           3                0   \n",
       "16              0                 0           1           2                0   \n",
       "17              0                 0           1           2                0   \n",
       "18              0                 0           1           2                0   \n",
       "19              0                 0           2           2                0   \n",
       "20              0                 0           1           2                0   \n",
       "21              0                 0           1           2                0   \n",
       "22              0                 0           1           3                0   \n",
       "23              0                 0           2           3                0   \n",
       "24              0                 0           2           3                0   \n",
       "25              0                 0           2           2                0   \n",
       "26              0                 0           2           2                0   \n",
       "27              0                 0           2           1                0   \n",
       "28              0                 0           2           2                0   \n",
       "29              0                 0           1           1                0   \n",
       "...           ...               ...         ...         ...              ...   \n",
       "82302           0                 0           1           2                0   \n",
       "82303           0                 0           1           2                0   \n",
       "82304           0                 0           1           1                0   \n",
       "82305           0                 0           1           1                0   \n",
       "82306           0                 0           1           1                0   \n",
       "82307           0                 0           2           2                0   \n",
       "82308           0                 0           2           2                0   \n",
       "82309           0                 0           1           2                0   \n",
       "82310           0                 0           1           2                0   \n",
       "82311           0                 0           1           2                0   \n",
       "82312           0                 0           1           1                0   \n",
       "82313           0                 0           1           1                0   \n",
       "82314           0                 0           1           1                0   \n",
       "82315           0                 0           1           2                0   \n",
       "82316           0                 0           2           2                0   \n",
       "82317           0                 0           1           4                0   \n",
       "82318           0                 0           1           2                0   \n",
       "82319           0                 0           1           4                0   \n",
       "82320           0                 0           1           2                0   \n",
       "82321           0                 0           1           2                0   \n",
       "82322           0                 0           1           1                0   \n",
       "82323           0                 0           1           3                0   \n",
       "82324           0                 0           1           2                0   \n",
       "82325           0                 0           1           2                0   \n",
       "82326           0                 0           1           1                0   \n",
       "82327           0                 0           2           1                0   \n",
       "82328           0                 0           3           2                0   \n",
       "82329           0                 0           1           1                1   \n",
       "82330           0                 0           1           1                1   \n",
       "82331           0                 0           1           1                0   \n",
       "\n",
       "       attack_cat  label  \n",
       "0          Normal      0  \n",
       "1          Normal      0  \n",
       "2          Normal      0  \n",
       "3          Normal      0  \n",
       "4          Normal      0  \n",
       "5          Normal      0  \n",
       "6          Normal      0  \n",
       "7          Normal      0  \n",
       "8          Normal      0  \n",
       "9          Normal      0  \n",
       "10         Normal      0  \n",
       "11         Normal      0  \n",
       "12         Normal      0  \n",
       "13         Normal      0  \n",
       "14         Normal      0  \n",
       "15         Normal      0  \n",
       "16         Normal      0  \n",
       "17         Normal      0  \n",
       "18         Normal      0  \n",
       "19         Normal      0  \n",
       "20         Normal      0  \n",
       "21         Normal      0  \n",
       "22         Normal      0  \n",
       "23         Normal      0  \n",
       "24         Normal      0  \n",
       "25         Normal      0  \n",
       "26         Normal      0  \n",
       "27         Normal      0  \n",
       "28         Normal      0  \n",
       "29         Normal      0  \n",
       "...           ...    ...  \n",
       "82302      Normal      0  \n",
       "82303      Normal      0  \n",
       "82304      Normal      0  \n",
       "82305      Normal      0  \n",
       "82306      Normal      0  \n",
       "82307      Normal      0  \n",
       "82308      Normal      0  \n",
       "82309      Normal      0  \n",
       "82310      Normal      0  \n",
       "82311      Normal      0  \n",
       "82312      Normal      0  \n",
       "82313      Normal      0  \n",
       "82314      Normal      0  \n",
       "82315      Normal      0  \n",
       "82316      Normal      0  \n",
       "82317      Normal      0  \n",
       "82318      Normal      0  \n",
       "82319      Normal      0  \n",
       "82320      Normal      0  \n",
       "82321      Normal      0  \n",
       "82322      Normal      0  \n",
       "82323      Normal      0  \n",
       "82324      Normal      0  \n",
       "82325      Normal      0  \n",
       "82326      Normal      0  \n",
       "82327      Normal      0  \n",
       "82328      Normal      0  \n",
       "82329      Normal      0  \n",
       "82330      Normal      0  \n",
       "82331      Normal      0  \n",
       "\n",
       "[82332 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('UNSWNB15_dataset/UNSW_NB15_training-set.csv')\n",
    "test_data = pd.read_csv('UNSWNB15_dataset/UNSW_NB15_testing-set.csv')\n",
    "train_data[train_data['service']!='-']\n",
    "cols_to_transform = ['proto', 'service', 'state']\n",
    "#train_data = pd.get_dummies(data = train_data, columns = cols_to_transform)\n",
    "#test_data = pd.get_dummies(data = test_data, columns = cols_to_transform)\n",
    "train_data.dtypes\n",
    "#train_data[['label','attack_cat']][train_data['attack_cat']!='Dos'].head(10000)\n",
    "obj_df = train_data.select_dtypes(include=['object']).copy()\n",
    "for col in cols_to_transform:\n",
    "    train_data[col]= train_data[col].astype('category').cat.codes\n",
    "    test_data[col]= test_data[col].astype('category').cat.codes\n",
    "train_data_ = train_data.drop(['id','attack_cat'], axis=1)\n",
    "test_data_ = test_data.drop(['id','attack_cat'], axis=1)\n",
    "train_data_ = train_data_.as_matrix(columns = None)\n",
    "test_data_ = test_data_.as_matrix(columns = None)\n",
    "test_data_.shape\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.83333367e-07, 9.00000000e-01, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 1.63934426e-02, 0.00000000e+00],\n",
       "        [1.33333358e-07, 9.00000000e-01, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 1.63934426e-02, 0.00000000e+00],\n",
       "        [8.33333486e-08, 9.00000000e-01, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 3.27868852e-02, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 4.61538462e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "        [0.00000000e+00, 4.61538462e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "        [1.50000028e-07, 9.00000000e-01, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       " array([0., 0., 0., ..., 0., 0., 0.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train= train_data_[:,:-1]\n",
    "y_train = train_data_[:,-1]\n",
    "x_test = test_data_[:,:-1]\n",
    "y_test = test_data_[:,-1]\n",
    "x_min = []\n",
    "x_max = []\n",
    "for i in range(x_train.shape[1]):\n",
    "    x_min.append(np.min(x_train[:,i]))\n",
    "    x_max.append(np.max(x_train[:,i]))\n",
    "x_max = np.array(x_max)\n",
    "x_min = np.array(x_min)\n",
    "x_train = (x_train - x_min)/(x_max-x_min)\n",
    "x_test = (x_test - x_min)/(x_max-x_min)\n",
    "x_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "dim_size = 40\n",
    "epochs = 200\n",
    "num_seq = 30\n",
    "# Batch Size\n",
    "batch_size =200\n",
    "# RNN Size\n",
    "rnn_size =50\n",
    "# Learning Rate\n",
    "learning_rate = 0.0005\n",
    "num_layers = 4\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 100\n",
    "keep_prob = 0.6\n",
    "relu_size = 20\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "save_dir = './save'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components = dim_size)\n",
    "x_reduced = svd.fit_transform(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.02463370e-03, 8.69230769e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.08317020e-02, 8.69230769e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 8.19672131e-02, 0.00000000e+00],\n",
       "       [2.70521550e-02, 8.69230769e-01, 0.00000000e+00, ...,\n",
       "        1.69491525e-02, 8.19672131e-02, 0.00000000e+00],\n",
       "       ...,\n",
       "       [1.50000028e-07, 9.15384615e-01, 1.66666667e-01, ...,\n",
       "        3.38983051e-02, 1.80327869e-01, 0.00000000e+00],\n",
       "       [1.50000028e-07, 9.15384615e-01, 1.66666667e-01, ...,\n",
       "        4.91525424e-01, 4.75409836e-01, 0.00000000e+00],\n",
       "       [1.50000028e-07, 9.15384615e-01, 1.66666667e-01, ...,\n",
       "        4.91525424e-01, 4.75409836e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_reduced = svd.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82332, 42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(arr,y, num_seq):\n",
    "    \n",
    "    new_arr = np.zeros((arr.shape[0],num_seq,arr.shape[1]))\n",
    "    new_y = np.zeros(arr.shape[0])\n",
    "    for i in range(arr.shape[0]-num_seq):\n",
    "        for j in range(num_seq):\n",
    "            new_arr[i,j,:] = arr[i+j,:]\n",
    "        new_y[i] = y[i+num_seq-1]\n",
    "    x_resampled ,y_resampled = SMOTE().fit_sample(np.reshape(new_arr,[-1,num_seq*arr.shape[1]]), new_y)\n",
    "    x_resampled = np.reshape(x_resampled,[-1,num_seq,arr.shape[1]])\n",
    "    return x_resampled,y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_resampled = []\n",
    "y_resampled = []\n",
    "for i in range(3):\n",
    "    x_resampledi, y_resampledi = resample(x_reduced[i*25000:25000*(i+1)], y_train[i*25000:25000*(i+1)],num_seq)\n",
    "    x_resampled.append(x_resampledi)\n",
    "    y_resampled.append(y_resampledi)\n",
    "#x_resampledj,y_resampledj = resample(x_reduced[75000:], y_train[75000:],num_seq)\n",
    "#x_resampled.append(x_resampledj)\n",
    "#y_resampled.append(y_resampledj)\n",
    "x_resampled = np.array(np.concatenate(x_resampled, axis = 0))    \n",
    "y_resampled = np.array(np.concatenate(y_resampled, axis = 0))\n",
    "from random import shuffle\n",
    "ind_list = [i for i in range(x_resampled.shape[0])]\n",
    "shuffle(ind_list)\n",
    "x_train_ = x_resampled[ind_list]\n",
    "y_train_ = y_resampled[ind_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50065"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid = x_train_[-40000:]\n",
    "y_valid = y_train_[-40000:]\n",
    "train_x = x_train_[:-40000]\n",
    "train_y = y_train_[:-40000]\n",
    "x_train.shape\n",
    "np.mean(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.83333367e-07, 9.00000000e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.63934426e-02, 0.00000000e+00],\n",
       "       [1.33333358e-07, 9.00000000e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.63934426e-02, 0.00000000e+00],\n",
       "       [8.33333486e-08, 9.00000000e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 3.27868852e-02, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 4.61538462e-02, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 4.61538462e-02, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.50000028e-07, 9.00000000e-01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batches(arr,y, batch_size):\n",
    "    n_batches = arr.shape[0]//batch_size\n",
    "    for i in range(0,n_batches*batch_size,batch_size):\n",
    "        x = arr[i:i+batch_size,:,:]\n",
    "        y_ = y[i:i+batch_size]\n",
    "        yield x,y_\n",
    "x,y = next(get_batches(train_x, train_y, batch_size))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 2.11737297e+00, -4.54734873e-01, -4.38193762e-01, ...,\n",
       "          -4.62860741e-04, -3.25086674e-04, -7.60591623e-05],\n",
       "         [ 1.99336642e+00, -7.64171994e-01,  3.06655465e-01, ...,\n",
       "          -2.08592802e-03,  9.76640742e-04, -4.61669324e-04],\n",
       "         [ 1.97200757e+00, -8.73143555e-01,  1.50674535e-01, ...,\n",
       "          -1.16913444e-03,  7.29940067e-04, -3.99962590e-04],\n",
       "         ...,\n",
       "         [ 2.26161161e+00, -4.95562996e-01, -3.61075481e-01, ...,\n",
       "          -2.80127013e-04, -9.11095676e-05, -1.20288109e-04],\n",
       "         [ 2.32103268e+00, -5.36507154e-01, -2.76528765e-01, ...,\n",
       "          -2.97933200e-04,  1.34340923e-04, -1.90675145e-04],\n",
       "         [ 1.09464340e+00,  9.02895936e-01, -2.69959244e-01, ...,\n",
       "          -2.20763896e-04,  2.86660593e-04, -8.28627084e-05]],\n",
       " \n",
       "        [[ 1.99336642e+00, -7.64171994e-01,  3.06655465e-01, ...,\n",
       "          -2.08592802e-03,  9.76640742e-04, -4.61669324e-04],\n",
       "         [ 1.97200757e+00, -8.73143555e-01,  1.50674535e-01, ...,\n",
       "          -1.16913444e-03,  7.29940067e-04, -3.99962590e-04],\n",
       "         [ 1.82572411e+00, -7.30267123e-01, -1.94414464e-02, ...,\n",
       "          -7.79281330e-04, -8.57053868e-04,  1.01028552e-04],\n",
       "         ...,\n",
       "         [ 2.32103268e+00, -5.36507154e-01, -2.76528765e-01, ...,\n",
       "          -2.97933200e-04,  1.34340923e-04, -1.90675145e-04],\n",
       "         [ 1.09464340e+00,  9.02895936e-01, -2.69959244e-01, ...,\n",
       "          -2.20763896e-04,  2.86660593e-04, -8.28627084e-05],\n",
       "         [ 1.85735153e+00, -7.41729169e-01,  1.05594652e-01, ...,\n",
       "          -9.97151463e-04,  7.20338086e-04, -2.63030748e-04]],\n",
       " \n",
       "        [[ 1.97200757e+00, -8.73143555e-01,  1.50674535e-01, ...,\n",
       "          -1.16913444e-03,  7.29940067e-04, -3.99962590e-04],\n",
       "         [ 1.82572411e+00, -7.30267123e-01, -1.94414464e-02, ...,\n",
       "          -7.79281330e-04, -8.57053868e-04,  1.01028552e-04],\n",
       "         [ 2.33367294e+00, -1.69320308e-01,  1.97540561e-02, ...,\n",
       "          -2.01286287e-04, -1.51757072e-04, -1.79216441e-04],\n",
       "         ...,\n",
       "         [ 1.09464340e+00,  9.02895936e-01, -2.69959244e-01, ...,\n",
       "          -2.20763896e-04,  2.86660593e-04, -8.28627084e-05],\n",
       "         [ 1.85735153e+00, -7.41729169e-01,  1.05594652e-01, ...,\n",
       "          -9.97151463e-04,  7.20338086e-04, -2.63030748e-04],\n",
       "         [ 1.94404000e+00, -8.04678387e-01,  7.71970425e-02, ...,\n",
       "           2.79513408e-04, -5.47824630e-04,  9.31720329e-05]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1.71390899e+00, -7.56325437e-01,  6.15907144e-01, ...,\n",
       "           1.68321670e-03, -1.64278039e-03, -5.22217746e-04],\n",
       "         [ 1.29129896e+00,  1.41962739e+00,  4.27978761e-01, ...,\n",
       "          -1.37365856e-04,  1.79202670e-04, -2.45771463e-04],\n",
       "         [ 1.27400199e+00,  1.41912115e+00,  4.39290126e-01, ...,\n",
       "          -1.46190327e-04,  1.81927505e-04, -2.45159113e-04],\n",
       "         ...,\n",
       "         [ 1.52107547e+00, -4.65908995e-01,  6.02466613e-01, ...,\n",
       "          -1.16451893e-03,  3.90799426e-05,  5.81081977e-05],\n",
       "         [ 1.28320726e+00,  1.42665177e+00,  4.44599295e-01, ...,\n",
       "          -1.35207850e-04,  1.76285487e-04, -2.46883705e-04],\n",
       "         [ 1.51172802e+00, -5.58398407e-01,  5.53126952e-01, ...,\n",
       "          -5.86158642e-04,  5.59818852e-04, -3.61484685e-04]],\n",
       " \n",
       "        [[ 1.29129896e+00,  1.41962739e+00,  4.27978761e-01, ...,\n",
       "          -1.37365856e-04,  1.79202670e-04, -2.45771463e-04],\n",
       "         [ 1.27400199e+00,  1.41912115e+00,  4.39290126e-01, ...,\n",
       "          -1.46190327e-04,  1.81927505e-04, -2.45159113e-04],\n",
       "         [ 1.63236292e+00, -6.51918741e-01,  6.54759261e-01, ...,\n",
       "           6.97713454e-04, -1.39401207e-03, -4.43229077e-04],\n",
       "         ...,\n",
       "         [ 1.28320726e+00,  1.42665177e+00,  4.44599295e-01, ...,\n",
       "          -1.35207850e-04,  1.76285487e-04, -2.46883705e-04],\n",
       "         [ 1.51172802e+00, -5.58398407e-01,  5.53126952e-01, ...,\n",
       "          -5.86158642e-04,  5.59818852e-04, -3.61484685e-04],\n",
       "         [ 1.28887090e+00,  1.41650340e+00,  4.38758156e-01, ...,\n",
       "          -1.27133031e-04,  2.69421324e-04, -2.37158420e-04]],\n",
       " \n",
       "        [[ 1.27400199e+00,  1.41912115e+00,  4.39290126e-01, ...,\n",
       "          -1.46190327e-04,  1.81927505e-04, -2.45159113e-04],\n",
       "         [ 1.63236292e+00, -6.51918741e-01,  6.54759261e-01, ...,\n",
       "           6.97713454e-04, -1.39401207e-03, -4.43229077e-04],\n",
       "         [ 1.29274734e+00,  1.41851957e+00,  4.26802342e-01, ...,\n",
       "          -1.35865643e-04,  1.90827605e-04, -2.44646903e-04],\n",
       "         ...,\n",
       "         [ 1.51172802e+00, -5.58398407e-01,  5.53126952e-01, ...,\n",
       "          -5.86158642e-04,  5.59818852e-04, -3.61484685e-04],\n",
       "         [ 1.28887090e+00,  1.41650340e+00,  4.38758156e-01, ...,\n",
       "          -1.27133031e-04,  2.69421324e-04, -2.37158420e-04],\n",
       "         [ 1.27625324e+00,  1.42639755e+00,  4.49152233e-01, ...,\n",
       "          -1.38411513e-04,  1.80224456e-04, -2.46468689e-04]]]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_test_batches(arr,y, batch_size, num_seq=num_seq):\n",
    "    new_arr = np.zeros((arr.shape[0],num_seq,arr.shape[1]))\n",
    "    new_y = np.zeros(arr.shape[0])\n",
    "    for i in range(arr.shape[0]-num_seq):\n",
    "        for j in range(num_seq):\n",
    "            new_arr[i,j,:] = arr[i+j,:]\n",
    "        new_y[i] = y[i+num_seq-1]\n",
    "    n_batches = arr.shape[0]//batch_size\n",
    "    for i in range(0,n_batches*batch_size,batch_size):\n",
    "        x = new_arr[i:i+batch_size,:,:]\n",
    "        y = new_y[i:i+batch_size]\n",
    "        yield x,y\n",
    "next(get_test_batches(x_test_reduced, y_test,100))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inputs(batch_size, num_inputs = 100 ):\n",
    "    inputs = tf.placeholder(tf.float32, [None,num_inputs,dim_size], name = 'inputs')\n",
    "    outputs = tf.placeholder(tf.int32, [None,],name = 'targets')\n",
    "    keep_prob = tf.placeholder(tf.float32, name = 'keep_prob')\n",
    "    return inputs, outputs, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, num_layers, batch_size, keep_prob):\n",
    "    ''' Build LSTM cell.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        keep_prob: Scalar tensor (tf.placeholder) for the dropout keep probability\n",
    "        lstm_size: Size of the hidden layers in the LSTM cells\n",
    "        num_layers: Number of LSTM layers\n",
    "        batch_size: Batch size\n",
    "\n",
    "    '''\n",
    "    ### Build the LSTM Cell\n",
    "    \n",
    "    def build_cell(lstm_size, keep_prob):\n",
    "        # Use a basic LSTM cell\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        \n",
    "        # Add dropout to the cell\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return drop\n",
    "    \n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([build_cell(lstm_size, keep_prob) for _ in range(num_layers)])\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    return cell, initial_state   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_output(lstm_output, in_size, out_size, relu_size = 100):\n",
    "    out = tf.contrib.layers.fully_connected(lstm_output, relu_size, activation_fn = tf.nn.relu)\n",
    "    out = tf.layers.batch_normalization(out)\n",
    "    logits = tf.contrib.layers.fully_connected(out,out_size, activation_fn=None)\n",
    "    #logits = tf.reshape(logits, (-1,10,3, out_size))\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loss(logits, targets,vocab_size):\n",
    "    ''' Calculate the loss from the logits and the targets.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        logits: Logits from final fully connected layer\n",
    "        targets: Targets for supervised learning\n",
    "        lstm_size: Number of LSTM hidden units\n",
    "        num_classes: Number of classes in targets\n",
    "        \n",
    "    '''\n",
    "    \n",
    "      # One-hot encode targets and reshape to match logits, one row per batch_size per step\n",
    "    #logits = tf.reshape(logits,[-1,vocab_size])\n",
    "    y_one_hot = tf.one_hot(targets, vocab_size)\n",
    "    #y_reshaped = tf.reshape(y_one_hot, logits.get_shape())\n",
    "    #y_reshaped = tf.reduce_sum(y_one_hot, axis = 1)\n",
    "    # Softmax cross entropy loss\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_one_hot)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss, y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, grad_clip):\n",
    "    ''' Build optmizer for training, using gradient clipping.\n",
    "    \n",
    "        Arguments:\n",
    "        loss: Network loss\n",
    "        learning_rate: Learning rate for optimizer\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    \n",
    "    def __init__(self, vocab_size, relu_size, batch_size=64,\n",
    "                       lstm_size=128, num_layers=2, learning_rate=0.001, \n",
    "                       grad_clip=5):\n",
    "    \n",
    "        # When we're using this network for sampling later, we'll be passing in\n",
    "        # one character at a time, so providing an option for that\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Build the input placeholder tensors\n",
    "        self.inputs, self.targets, self.keep_prob = build_inputs(batch_size, num_inputs = num_seq )\n",
    "\n",
    "        # Build the LSTM cell\n",
    "        cell, self.initial_state = build_lstm(lstm_size, num_layers, batch_size, self.keep_prob)\n",
    "\n",
    "        ### Run the data through the RNN layers\n",
    "        # First, one-hot encode the input tokens\n",
    "       \n",
    "        \n",
    "        # Run each sequence step through the RNN and collect the outputs\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell, self.inputs, initial_state=self.initial_state)\n",
    "        self.final_state = state\n",
    "        \n",
    "        # Get softmax predictions and logits\n",
    "        self.logits = build_output(outputs, lstm_size, vocab_size, relu_size = relu_size)[:,-1]\n",
    "        \n",
    "        # Loss and optimizer (with gradient clipping)\n",
    "        self.loss, self.y_reshaped = build_loss(self.logits, self.targets, vocab_size)\n",
    "        self.pred = tf.argmax(self.logits,1)\n",
    "        #_,self.pred = tf.nn.top_k(self.logits,3)\n",
    "        correct_pred = tf.equal(self.pred, tf.argmax(self.y_reshaped,1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        self.optimizer = build_optimizer(self.loss, learning_rate, grad_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-67f0b3d35e26>:19: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "epoch 0: Training loss : 0.457426\n",
      "Validation loss : 0.394261\n",
      "epoch 1: Training loss : 0.306372\n",
      "Validation loss : 0.218551\n",
      "epoch 2: Training loss : 0.224340\n",
      "Validation loss : 0.207967\n",
      "epoch 3: Training loss : 0.201930\n",
      "Validation loss : 0.181982\n",
      "epoch 4: Training loss : 0.194980\n",
      "Validation loss : 0.174965\n",
      "epoch 5: Training loss : 0.188409\n",
      "Validation loss : 0.183822\n",
      "epoch 6: Training loss : 0.182877\n",
      "Validation loss : 0.186902\n",
      "epoch 7: Training loss : 0.176397\n",
      "Validation loss : 0.148297\n",
      "epoch 8: Training loss : 0.170958\n",
      "Validation loss : 0.147477\n",
      "epoch 9: Training loss : 0.173400\n",
      "Validation loss : 0.158915\n",
      "epoch 10: Training loss : 0.168600\n",
      "Validation loss : 0.160263\n",
      "epoch 11: Training loss : 0.166114\n",
      "Validation loss : 0.139857\n",
      "epoch 12: Training loss : 0.162067\n",
      "Validation loss : 0.163470\n",
      "epoch 13: Training loss : 0.163187\n",
      "Validation loss : 0.165525\n",
      "epoch 14: Training loss : 0.160718\n",
      "Validation loss : 0.137065\n",
      "epoch 15: Training loss : 0.154864\n",
      "Validation loss : 0.133133\n",
      "epoch 16: Training loss : 0.154065\n",
      "Validation loss : 0.162270\n",
      "epoch 17: Training loss : 0.158643\n",
      "Validation loss : 0.156010\n",
      "epoch 18: Training loss : 0.148005\n",
      "Validation loss : 0.146609\n",
      "epoch 19: Training loss : 0.150756\n",
      "Validation loss : 0.143517\n",
      "epoch 20: Training loss : 0.146031\n",
      "Validation loss : 0.125319\n",
      "epoch 21: Training loss : 0.148990\n",
      "Validation loss : 0.137851\n",
      "epoch 22: Training loss : 0.143202\n",
      "Validation loss : 0.129709\n",
      "epoch 23: Training loss : 0.150652\n",
      "Validation loss : 0.138215\n",
      "epoch 24: Training loss : 0.145769\n",
      "Validation loss : 0.130395\n",
      "epoch 25: Training loss : 0.150506\n",
      "Validation loss : 0.147370\n",
      "epoch 26: Training loss : 0.142184\n",
      "Validation loss : 0.133788\n",
      "epoch 27: Training loss : 0.141577\n",
      "Validation loss : 0.121993\n",
      "epoch 28: Training loss : 0.139305\n",
      "Validation loss : 0.168850\n",
      "epoch 29: Training loss : 0.137512\n",
      "Validation loss : 0.123617\n",
      "epoch 30: Training loss : 0.137178\n",
      "Validation loss : 0.129036\n",
      "epoch 31: Training loss : 0.131502\n",
      "Validation loss : 0.113339\n",
      "epoch 32: Training loss : 0.129904\n",
      "Validation loss : 0.122887\n",
      "epoch 33: Training loss : 0.129736\n",
      "Validation loss : 0.111044\n",
      "epoch 34: Training loss : 0.124868\n",
      "Validation loss : 0.114930\n",
      "epoch 35: Training loss : 0.125256\n",
      "Validation loss : 0.124547\n",
      "epoch 36: Training loss : 0.123203\n",
      "Validation loss : 0.116345\n",
      "epoch 37: Training loss : 0.122139\n",
      "Validation loss : 0.128074\n",
      "epoch 38: Training loss : 0.119209\n",
      "Validation loss : 0.114204\n",
      "epoch 39: Training loss : 0.122722\n",
      "Validation loss : 0.102482\n",
      "epoch 40: Training loss : 0.121028\n",
      "Validation loss : 0.124529\n",
      "epoch 41: Training loss : 0.117615\n",
      "Validation loss : 0.114648\n",
      "epoch 42: Training loss : 0.117710\n",
      "Validation loss : 0.101643\n",
      "epoch 43: Training loss : 0.117070\n",
      "Validation loss : 0.108028\n",
      "epoch 44: Training loss : 0.117238\n",
      "Validation loss : 0.107577\n",
      "epoch 45: Training loss : 0.114672\n",
      "Validation loss : 0.104485\n",
      "epoch 46: Training loss : 0.110181\n",
      "Validation loss : 0.110799\n",
      "epoch 47: Training loss : 0.112743\n",
      "Validation loss : 0.103475\n",
      "epoch 48: Training loss : 0.114288\n",
      "Validation loss : 0.098424\n",
      "epoch 49: Training loss : 0.112447\n",
      "Validation loss : 0.107175\n",
      "epoch 50: Training loss : 0.110079\n",
      "Validation loss : 0.108549\n",
      "epoch 51: Training loss : 0.111236\n",
      "Validation loss : 0.095551\n",
      "epoch 52: Training loss : 0.111967\n",
      "Validation loss : 0.102748\n",
      "epoch 53: Training loss : 0.111628\n",
      "Validation loss : 0.100643\n",
      "epoch 54: Training loss : 0.104366\n",
      "Validation loss : 0.095398\n",
      "epoch 55: Training loss : 0.111040\n",
      "Validation loss : 0.102397\n",
      "epoch 56: Training loss : 0.102685\n",
      "Validation loss : 0.105127\n",
      "epoch 57: Training loss : 0.108571\n",
      "Validation loss : 0.118001\n",
      "epoch 58: Training loss : 0.105179\n",
      "Validation loss : 0.094309\n",
      "epoch 59: Training loss : 0.110531\n",
      "Validation loss : 0.098620\n",
      "epoch 60: Training loss : 0.105160\n",
      "Validation loss : 0.104759\n",
      "epoch 61: Training loss : 0.106214\n",
      "Validation loss : 0.094964\n",
      "epoch 62: Training loss : 0.105916\n",
      "Validation loss : 0.099767\n",
      "epoch 63: Training loss : 0.101354\n",
      "Validation loss : 0.098935\n",
      "epoch 64: Training loss : 0.101897\n",
      "Validation loss : 0.109903\n",
      "epoch 65: Training loss : 0.102859\n",
      "Validation loss : 0.101679\n",
      "epoch 66: Training loss : 0.098167\n",
      "Validation loss : 0.094177\n",
      "epoch 67: Training loss : 0.104560\n",
      "Validation loss : 0.126950\n",
      "epoch 68: Training loss : 0.102419\n",
      "Validation loss : 0.094756\n",
      "epoch 69: Training loss : 0.100523\n",
      "Validation loss : 0.111881\n",
      "epoch 70: Training loss : 0.101235\n",
      "Validation loss : 0.097571\n",
      "epoch 71: Training loss : 0.102579\n",
      "Validation loss : 0.094940\n",
      "epoch 72: Training loss : 0.100813\n",
      "Validation loss : 0.101972\n",
      "epoch 73: Training loss : 0.101346\n",
      "Validation loss : 0.092721\n",
      "epoch 74: Training loss : 0.099881\n",
      "Validation loss : 0.091074\n",
      "epoch 75: Training loss : 0.097748\n",
      "Validation loss : 0.099427\n",
      "epoch 76: Training loss : 0.099969\n",
      "Validation loss : 0.091676\n",
      "epoch 77: Training loss : 0.095309\n",
      "Validation loss : 0.106876\n",
      "epoch 78: Training loss : 0.096965\n",
      "Validation loss : 0.097661\n",
      "epoch 79: Training loss : 0.095944\n",
      "Validation loss : 0.091059\n",
      "epoch 80: Training loss : 0.097038\n",
      "Validation loss : 0.090580\n",
      "epoch 81: Training loss : 0.098786\n",
      "Validation loss : 0.087839\n",
      "epoch 82: Training loss : 0.096796\n",
      "Validation loss : 0.092646\n",
      "epoch 83: Training loss : 0.100375\n",
      "Validation loss : 0.104724\n",
      "epoch 84: Training loss : 0.099168\n",
      "Validation loss : 0.093075\n",
      "epoch 85: Training loss : 0.095887\n",
      "Validation loss : 0.093288\n",
      "epoch 86: Training loss : 0.095351\n",
      "Validation loss : 0.105465\n",
      "epoch 87: Training loss : 0.093318\n",
      "Validation loss : 0.089554\n",
      "epoch 88: Training loss : 0.095717\n",
      "Validation loss : 0.091134\n",
      "epoch 89: Training loss : 0.094086\n",
      "Validation loss : 0.086059\n",
      "epoch 90: Training loss : 0.091813\n",
      "Validation loss : 0.103231\n",
      "epoch 91: Training loss : 0.092126\n",
      "Validation loss : 0.091060\n",
      "epoch 92: Training loss : 0.092422\n",
      "Validation loss : 0.086696\n",
      "epoch 93: Training loss : 0.091122\n",
      "Validation loss : 0.093817\n",
      "epoch 94: Training loss : 0.090663\n",
      "Validation loss : 0.088996\n",
      "epoch 95: Training loss : 0.093261\n",
      "Validation loss : 0.093758\n",
      "epoch 96: Training loss : 0.089145\n",
      "Validation loss : 0.090236\n",
      "epoch 97: Training loss : 0.094023\n",
      "Validation loss : 0.091347\n",
      "epoch 98: Training loss : 0.093315\n",
      "Validation loss : 0.095521\n",
      "epoch 99: Training loss : 0.090917\n",
      "Validation loss : 0.089314\n",
      "epoch 100: Training loss : 0.088707\n",
      "Validation loss : 0.098958\n",
      "epoch 101: Training loss : 0.090541\n",
      "Validation loss : 0.086651\n",
      "epoch 102: Training loss : 0.088427\n",
      "Validation loss : 0.090160\n",
      "epoch 103: Training loss : 0.092054\n",
      "Validation loss : 0.088702\n",
      "epoch 104: Training loss : 0.088031\n",
      "Validation loss : 0.087103\n",
      "epoch 105: Training loss : 0.089128\n",
      "Validation loss : 0.087232\n",
      "epoch 106: Training loss : 0.085851\n",
      "Validation loss : 0.087518\n",
      "epoch 107: Training loss : 0.086902\n",
      "Validation loss : 0.086687\n",
      "epoch 108: Training loss : 0.088574\n",
      "Validation loss : 0.103286\n",
      "epoch 109: Training loss : 0.090448\n",
      "Validation loss : 0.089265\n",
      "epoch 110: Training loss : 0.088362\n",
      "Validation loss : 0.088062\n",
      "epoch 111: Training loss : 0.086013\n",
      "Validation loss : 0.088044\n",
      "epoch 112: Training loss : 0.084915\n",
      "Validation loss : 0.088496\n",
      "epoch 113: Training loss : 0.084935\n",
      "Validation loss : 0.088992\n",
      "epoch 114: Training loss : 0.086714\n",
      "Validation loss : 0.091173\n",
      "epoch 115: Training loss : 0.084429\n",
      "Validation loss : 0.085904\n",
      "epoch 116: Training loss : 0.086885\n",
      "Validation loss : 0.088550\n",
      "epoch 117: Training loss : 0.086799\n",
      "Validation loss : 0.086692\n",
      "epoch 118: Training loss : 0.084191\n",
      "Validation loss : 0.087571\n",
      "epoch 119: Training loss : 0.087704\n",
      "Validation loss : 0.093418\n",
      "epoch 120: Training loss : 0.082782\n",
      "Validation loss : 0.089557\n",
      "epoch 121: Training loss : 0.082496\n",
      "Validation loss : 0.088096\n",
      "epoch 122: Training loss : 0.085012\n",
      "Validation loss : 0.089877\n",
      "epoch 123: Training loss : 0.087818\n",
      "Validation loss : 0.091399\n",
      "epoch 124: Training loss : 0.085575\n",
      "Validation loss : 0.088012\n",
      "epoch 125: Training loss : 0.082692\n",
      "Validation loss : 0.094776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126: Training loss : 0.086018\n",
      "Validation loss : 0.087669\n",
      "epoch 127: Training loss : 0.082072\n",
      "Validation loss : 0.088933\n",
      "epoch 128: Training loss : 0.083393\n",
      "Validation loss : 0.091763\n",
      "epoch 129: Training loss : 0.082675\n",
      "Validation loss : 0.088517\n",
      "epoch 130: Training loss : 0.082241\n",
      "Validation loss : 0.092250\n",
      "epoch 131: Training loss : 0.081705\n",
      "Validation loss : 0.088660\n",
      "epoch 132: Training loss : 0.082244\n",
      "Validation loss : 0.090968\n",
      "epoch 133: Training loss : 0.082974\n",
      "Validation loss : 0.091244\n",
      "epoch 134: Training loss : 0.081624\n",
      "Validation loss : 0.091822\n",
      "epoch 135: Training loss : 0.082990\n",
      "Validation loss : 0.108163\n",
      "epoch 136: Training loss : 0.081735\n",
      "Validation loss : 0.091542\n",
      "epoch 137: Training loss : 0.079726\n",
      "Validation loss : 0.102755\n",
      "epoch 138: Training loss : 0.080370\n",
      "Validation loss : 0.088619\n",
      "epoch 139: Training loss : 0.079596\n",
      "Validation loss : 0.092584\n",
      "epoch 140: Training loss : 0.078831\n",
      "Validation loss : 0.093349\n",
      "epoch 141: Training loss : 0.078706\n",
      "Validation loss : 0.089156\n",
      "epoch 142: Training loss : 0.077839\n",
      "Validation loss : 0.091406\n",
      "epoch 143: Training loss : 0.078385\n",
      "Validation loss : 0.089595\n",
      "epoch 144: Training loss : 0.078148\n",
      "Validation loss : 0.093484\n",
      "epoch 145: Training loss : 0.079716\n",
      "Validation loss : 0.098362\n",
      "epoch 146: Training loss : 0.079463\n",
      "Validation loss : 0.096450\n",
      "epoch 147: Training loss : 0.078892\n",
      "Validation loss : 0.092184\n",
      "epoch 148: Training loss : 0.076930\n",
      "Validation loss : 0.088744\n",
      "epoch 149: Training loss : 0.077388\n",
      "Validation loss : 0.090300\n",
      "epoch 150: Training loss : 0.077754\n",
      "Validation loss : 0.111478\n",
      "epoch 151: Training loss : 0.077697\n",
      "Validation loss : 0.092477\n",
      "epoch 152: Training loss : 0.076917\n",
      "Validation loss : 0.101868\n",
      "epoch 153: Training loss : 0.077211\n",
      "Validation loss : 0.092477\n",
      "epoch 154: Training loss : 0.075906\n",
      "Validation loss : 0.088619\n",
      "epoch 155: Training loss : 0.075040\n",
      "Validation loss : 0.105695\n",
      "epoch 156: Training loss : 0.075228\n",
      "Validation loss : 0.104598\n",
      "epoch 157: Training loss : 0.074486\n",
      "Validation loss : 0.097765\n",
      "epoch 158: Training loss : 0.074782\n",
      "Validation loss : 0.092035\n",
      "epoch 159: Training loss : 0.073516\n",
      "Validation loss : 0.092097\n",
      "epoch 160: Training loss : 0.074730\n",
      "Validation loss : 0.096353\n",
      "epoch 161: Training loss : 0.075540\n",
      "Validation loss : 0.096443\n",
      "epoch 162: Training loss : 0.075792\n",
      "Validation loss : 0.092877\n",
      "epoch 163: Training loss : 0.072570\n",
      "Validation loss : 0.091030\n",
      "epoch 164: Training loss : 0.077356\n",
      "Validation loss : 0.092431\n",
      "epoch 165: Training loss : 0.073737\n",
      "Validation loss : 0.093587\n",
      "epoch 166: Training loss : 0.071919\n",
      "Validation loss : 0.092083\n",
      "epoch 167: Training loss : 0.072902\n",
      "Validation loss : 0.093064\n",
      "epoch 168: Training loss : 0.072606\n",
      "Validation loss : 0.091006\n",
      "epoch 169: Training loss : 0.073296\n",
      "Validation loss : 0.117289\n",
      "epoch 170: Training loss : 0.073440\n",
      "Validation loss : 0.096679\n",
      "epoch 171: Training loss : 0.072792\n",
      "Validation loss : 0.097605\n",
      "epoch 172: Training loss : 0.072619\n",
      "Validation loss : 0.114419\n",
      "epoch 173: Training loss : 0.073775\n",
      "Validation loss : 0.101532\n",
      "epoch 174: Training loss : 0.073867\n",
      "Validation loss : 0.103811\n",
      "epoch 175: Training loss : 0.070900\n",
      "Validation loss : 0.095558\n",
      "epoch 176: Training loss : 0.072063\n",
      "Validation loss : 0.097240\n",
      "epoch 177: Training loss : 0.070903\n",
      "Validation loss : 0.102860\n",
      "epoch 178: Training loss : 0.070820\n",
      "Validation loss : 0.099878\n",
      "epoch 179: Training loss : 0.071608\n",
      "Validation loss : 0.094825\n",
      "epoch 180: Training loss : 0.070653\n",
      "Validation loss : 0.107339\n",
      "epoch 181: Training loss : 0.068973\n",
      "Validation loss : 0.096544\n",
      "epoch 182: Training loss : 0.070338\n",
      "Validation loss : 0.096890\n",
      "epoch 183: Training loss : 0.068881\n",
      "Validation loss : 0.104138\n",
      "epoch 184: Training loss : 0.069801\n",
      "Validation loss : 0.097004\n",
      "epoch 185: Training loss : 0.068330\n",
      "Validation loss : 0.109116\n",
      "epoch 186: Training loss : 0.069520\n",
      "Validation loss : 0.101353\n",
      "epoch 187: Training loss : 0.068849\n",
      "Validation loss : 0.099614\n",
      "epoch 188: Training loss : 0.070083\n",
      "Validation loss : 0.106976\n",
      "epoch 189: Training loss : 0.068210\n",
      "Validation loss : 0.100369\n",
      "epoch 190: Training loss : 0.067724\n",
      "Validation loss : 0.102647\n",
      "epoch 191: Training loss : 0.068380\n",
      "Validation loss : 0.102046\n",
      "epoch 192: Training loss : 0.068854\n",
      "Validation loss : 0.100759\n",
      "epoch 193: Training loss : 0.067121\n",
      "Validation loss : 0.099455\n",
      "epoch 194: Training loss : 0.066837\n",
      "Validation loss : 0.102561\n",
      "epoch 195: Training loss : 0.067254\n",
      "Validation loss : 0.100418\n",
      "epoch 196: Training loss : 0.065911\n",
      "Validation loss : 0.109031\n",
      "epoch 197: Training loss : 0.065905\n",
      "Validation loss : 0.105614\n",
      "epoch 198: Training loss : 0.066405\n",
      "Validation loss : 0.097405\n",
      "epoch 199: Training loss : 0.065886\n",
      "Validation loss : 0.102130\n",
      "Training accuracy : 97.54\n",
      "validation accuracy : 95.54\n",
      "Test accuracy : 92.99\n"
     ]
    }
   ],
   "source": [
    "save_every_n = 200\n",
    "\n",
    "model = RNN(2,relu_size, batch_size=batch_size,\n",
    "                lstm_size=rnn_size, num_layers=num_layers, \n",
    "                learning_rate=learning_rate)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Use the line below to load a checkpoint and resume training\n",
    "    #saver.restore(sess, 'checkpoints/______.ckpt')\n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        train_loss = []\n",
    "        \n",
    "        # Train network\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for x, y in get_batches(train_x, train_y,batch_size):\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: keep_prob,\n",
    "                    model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.loss, \n",
    "                                                 model.final_state, \n",
    "                                                 model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "            train_loss.append(batch_loss)\n",
    "            #if(counter%show_every_n_batches ==0):\n",
    "                #print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                  #'Training Step: {}... '.format(counter),\n",
    "                    #'Training loss: {:.4f}... '.format(batch_loss))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, num_layers))\n",
    "        val_loss = []\n",
    "        val_state = sess.run(model.initial_state)\n",
    "        for x, y in get_batches(x_valid, y_valid, batch_size):\n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: 1,\n",
    "                    model.initial_state: val_state}\n",
    "            batch_loss, val_state = sess.run([model.loss, \n",
    "                                                 model.final_state], \n",
    "                                                 feed_dict=feed)\n",
    "            \n",
    "                                                 \n",
    "            val_loss.append(batch_loss)\n",
    "            \n",
    "        print(\"epoch {}: Training loss : {:.6f}\".format(e, np.mean(train_loss)))\n",
    "        print(\"Validation loss : {:.6f}\".format(np.mean(val_loss)))\n",
    "        \n",
    "    val_acc = []\n",
    "    val_pred =[]\n",
    "    val_y = []\n",
    "    val_logits = []\n",
    "    val_state = sess.run(model.initial_state)\n",
    "    for x, y in get_batches(x_valid, y_valid,batch_size):\n",
    "        feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: 1,\n",
    "                    model.initial_state: val_state}\n",
    "        val_state,batch_pred,batch_acc,batch_logits = sess.run([model.final_state,model.pred,model.accuracy, model.logits], feed_dict = feed)\n",
    "        val_acc.append(batch_acc)\n",
    "        val_y.append(y)\n",
    "        val_pred.append(batch_pred)\n",
    "        val_logits.append(batch_logits)\n",
    "    train_pred =[]\n",
    "    train_label = []\n",
    "    train_acc = []\n",
    "    train_logits = []\n",
    "    train_state = sess.run(model.initial_state)\n",
    "    for x, y in get_batches(train_x, train_y,batch_size):\n",
    "        feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: 1,\n",
    "                    model.initial_state: train_state}\n",
    "        train_state,batch_pred,batch_acc, batch_logits = sess.run([model.final_state,model.pred,model.accuracy, model.logits], feed_dict = feed)\n",
    "        train_acc.append(batch_acc)\n",
    "        train_label.append(y)\n",
    "        train_pred.append(batch_pred)\n",
    "        train_logits.append(batch_logits)\n",
    "    print(\"Training accuracy : {:.2f}\".format(100*np.mean(train_acc)))    \n",
    "    print(\"validation accuracy : {:.2f}\".format(100*np.mean(val_acc)))\n",
    "    test_acc = []\n",
    "    test_pred =[]\n",
    "    test_y = []\n",
    "    test_logits = []\n",
    "    test_state = sess.run(model.initial_state)\n",
    "    for x, y in get_test_batches(x_test_reduced, y_test,batch_size,num_seq):\n",
    "        feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: 1,\n",
    "                    model.initial_state: val_state}\n",
    "        test_state,batch_pred,batch_acc, batch_logits = sess.run([model.final_state,model.pred,model.accuracy,model.logits], feed_dict = feed)\n",
    "        test_acc.append(batch_acc)\n",
    "        test_y.append(y)\n",
    "        test_pred.append(batch_pred)\n",
    "        test_logits.append(batch_logits)\n",
    "    print(\"Test accuracy : {:.2f}\".format(100*np.mean(test_acc))) \n",
    "    #val_pred = np.vstack(val_pred)\n",
    "    #val_y = np.vstack(val_y)\n",
    "    #print(mapk(val_y,val_pred))\n",
    "    saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, num_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18545.0 20026.0\n",
      "56 12263.0\n"
     ]
    }
   ],
   "source": [
    "y_ =[]\n",
    "print(np.sum([np.sum(pred)for pred in val_pred]), np.sum([np.sum(pred)for pred in val_y]))\n",
    "print(np.sum([np.sum(pred) for pred in test_pred]), np.sum([np.sum(pred) for pred in test_y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-3bbf9aba48c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mval_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "val_y = np.concatenate(val_y)\n",
    "test_y = np.concatenate(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18421, 124, 1605, 18421)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn,fp,fn,tp = confusion_matrix(val_y,val_pred).ravel()\n",
    "(tp,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9933135616069021,\n",
       " 0.006208070491639131,\n",
       " 0.9198541895535803,\n",
       " 0.9551735760026964,\n",
       " 0.95545)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DR = tp/(tp+fp)\n",
    "FAR = fp/(tn+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*(recall*DR)/(recall+DR)\n",
    "(DR,FAR,recall,f1,np.mean(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.30357142857142855,\n",
       " 0.00023935631563119488,\n",
       " 0.001386283943570089,\n",
       " 0.0027599642828151634,\n",
       " 0.9298801)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn,fp,fn,tp = confusion_matrix(test_y,np.concatenate(test_pred)).ravel()\n",
    "DR = tp/(tp+fp)\n",
    "FAR = fp/(tn+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*(recall*DR)/(recall+DR)\n",
    "(DR,FAR,recall,f1,np.mean(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.9749405919205012,\n",
       "  0.025056947608200455,\n",
       "  0.9757646041355452,\n",
       "  0.9753524239893904,\n",
       "  0.9298801),\n",
       " (49643, 1276, 1233, 49648))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn,fp,fn,tp = confusion_matrix(np.concatenate(train_label),np.concatenate(train_pred)).ravel()\n",
    "DR = tp/(tp+fp)\n",
    "FAR = fp/(tn+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*(recall*DR)/(recall+DR)\n",
    "(DR,FAR,recall,f1,np.mean(test_acc)), (tp,fp,fn,tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(np.concatenate(train_logits,0),np.concatenate(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18421, 124, 1605, 18421)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = clf.predict(np.concatenate(val_logits,0))\n",
    "tn,fp,fn,tp = confusion_matrix(y_valid,val_pred).ravel()\n",
    "(tp,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9933135616069021,\n",
       " 0.006208070491639131,\n",
       " 0.9198541895535803,\n",
       " 0.9551735760026964,\n",
       " 0.956775)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "DR = tp/(tp+fp)\n",
    "FAR = fp/(tn+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*(recall*DR)/(recall+DR)\n",
    "(DR,FAR,recall,f1,acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 7.978543854373163e-05, 0.0, nan, 0.929931506849315)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_ = clf.predict(np.concatenate(test_logits,0))\n",
    "tn,fp,fn,tp = confusion_matrix(test_y,test_pred_).ravel()\n",
    "acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "DR = tp/(tp+fp)\n",
    "FAR = fp/(tn+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*(recall*DR)/(recall+DR)\n",
    "(DR,FAR,recall,f1,acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9989462370123712,\n",
       " 0.0009818553138009583,\n",
       " 0.9316573630002358,\n",
       " 0.9641291634884311,\n",
       " 0.9653536345776031)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_ = clf.predict(np.concatenate(train_logits,0))\n",
    "tn,fp,fn,tp = confusion_matrix(np.concatenate(train_label),train_pred_).ravel()\n",
    "acc = (tp+tn)/(tp+tn+fp+fn)\n",
    "DR = tp/(tp+fp)\n",
    "FAR = fp/(tn+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*(recall*DR)/(recall+DR)\n",
    "(DR,FAR,recall,f1,acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
